{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.stats import logistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clusters and site parameters\n",
    "\n",
    "We will define 3 clusters, each with some number of member sites.\n",
    "\n",
    "The data-generating model follows a very simple premise:\n",
    "> Within each cluster, the sites will have a \"default\" or \"baseline\" RR (response-rate), except that certain sites will have much higher or much lower RR. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prob of each cluster occurring\n",
    "p_c = np.array([0.2, 0.2, 0.6]) \n",
    "\n",
    "n_c = len(p_c)  # num clusters\n",
    "\n",
    "# default/baseline response-rate for sites in each cluster\n",
    "rr_c_def = np.array([0.2, 0.6, 0.1]) \n",
    "\n",
    "# convert these to logits, think of them as \"cluster weights\"\n",
    "w_c = np.log(rr_c_def / (1 - rr_c_def)) \n",
    "\n",
    "p_s = [ np.array([0.1, 0.1, 0.1, 0.1, 0.1, 0.5]),  # site occurrence probabilities, in each cluster\n",
    "        np.array([0.3, 0.3, 0.4]),\n",
    "        np.array([0.2, 0.2, 0.6])\n",
    "        ]\n",
    "\n",
    "\n",
    "# Each site_id adds to the cluster's baseline logit;\n",
    "# Cluster members generally have cluster's baseline RR,\n",
    "# except for some that are \"much higher\" or \"much lower\".\n",
    "# We cannot express this in probabilities easily (since they need to be in [0,1]\n",
    "# but in logit (or log-oods) space this is easy.\n",
    "# Think of these as \"incremental\" site_weights, relative to their cluster-weight\n",
    "# So we name these as \"d_w_s\" , signifying \"delta site weight\"\n",
    "d_w_s = [ np.array( [0.0, 0.0, 2.0, 0.0, 0.0, 0.0]),  # cluster 1\n",
    "          np.array( [0.0, 0.0, 0.0]),  # cluster 2\n",
    "          np.array( [0.0, -5.0, 0.0])  # cluster 3\n",
    "          ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### True model with site + cluster indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.38629436,  0.40546511, -2.19722458,  0.        ,  0.        ,\n",
       "        2.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        , -5.        ,  0.        ])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# site + cluster model with these indicator variables:\n",
    "# c_1, c_2, c_3, \n",
    "# s_11, s_12, s_13, s_14, s_15, s_16, \n",
    "# s_21, s_21, s_23, \n",
    "# s_31, s_32, s_33\n",
    "\n",
    "w_site = np.concatenate( [ d_w_s[i] for i in range(n_c)] )\n",
    "w_sc = np.concatenate((w_c, w_site))\n",
    "w_sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equivalent true model with sites only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.38629436, -1.38629436,  0.61370564, -1.38629436, -1.38629436,\n",
       "       -1.38629436,  0.40546511,  0.40546511,  0.40546511, -2.19722458,\n",
       "       -7.19722458, -2.19722458])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## convert (cluster + sites) weight-vector to (site-only) weights\n",
    "def site_weights(wts):\n",
    "    w_clusters = wts[:n_c]\n",
    "    w_sites = wts[n_c:]\n",
    "    w_clusters_rep = np.concatenate( [  [ w_clusters[i] ] * len (p_s[i]) for i in range(n_c)])\n",
    "    return w_sites + w_clusters_rep\n",
    "\n",
    "w_s = site_weights(w_sc )\n",
    "w_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### True logistic model\n",
    "\n",
    "Now each site's response-rate is a function of its logit (weight) `w_s`  , and a cluster response rate is given by this expression, but we don't really care about the \"cluster response rate\" since it's just a blend of its member sites' responses rates\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "p(y=1 | c=1) &= p(y=1 | s=11) p(s=11 | c=1) +  \\\\\n",
    "             &= p(y=1 | s=12) p(s=12 | c=1) + \\\\\n",
    "             &= p(y=1 | s=13) p(s=13 | c=1)\n",
    "\\end{align}\n",
    "$$\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# site response-rate, based on logistic with weights w_s\n",
    "# logit for a given cluster and one of its sites\n",
    "def logit_site(cluster, site):\n",
    "    return w_c[cluster] + d_w_s[cluster][site]\n",
    "\n",
    "# site response_rate, according to logistic model with true weights\n",
    "def rr_s(cluster, site):\n",
    "    return logistic.cdf(logit_site(cluster, site))\n",
    "\n",
    "# cluster response rate, according to logistic model, and site-occurrence probs\n",
    "def rr_c(cluster):\n",
    "    return sum( [ rr_s(cluster,i) * p_s[cluster][i] for i in range(len(p_s[cluster]))]  ) \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Site response-rates\n",
    "Note how this matches what we wanted to model, i.e. in each cluster sites have a certain \"baseline\" response rate (RR), and some have much higher or much lower RR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.2, 0.2, 0.6488, 0.2, 0.2, 0.2], [0.6, 0.6, 0.6], [0.1, 0.0007, 0.1]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ [ np.round(rr_s(c, i),4) for i in range( len(p_s[c]))] for c in range(n_c) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster response-rates\n",
    "\n",
    "\n",
    "             \n",
    "              \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.24487856442839395, 0.6, 0.08014962014080428]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RR of each cluster, from model\n",
    "\n",
    "[ rr_c(c) for c in range(n_c) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data gen \n",
    "We generate N rows with one-hot encoded clusters and sites:\n",
    "\n",
    "`c_1, c_2, c_3, s_11, s_12, s_13, s_21, s_21, s_23, s_31, s_32, s_33, label`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(n, i):\n",
    "    x = np.array([0] * n)\n",
    "    x[i] = 1.0\n",
    "    return x\n",
    "\n",
    "\n",
    "# site-indicator variables for all clusters,\n",
    "# given that a specific cluster and its site occur\n",
    "def site_hot(cluster, site):\n",
    "    nc = len(p_c)\n",
    "    ns = len(p_s[cluster])  # num sites in this cluster\n",
    "    return np.concatenate(\n",
    "        [one_hot(len(p_s[c]), site)\n",
    "         if c == cluster\n",
    "         else one_hot(len(p_s[c]), 0) * 0\n",
    "         for c in range(nc)]\n",
    "    )\n",
    "\n",
    "\n",
    "# encode data-row given cluster index, site_index in cluster\n",
    "def encode(cluster, site):\n",
    "    nc = len(p_c)\n",
    "    cluster_hot = one_hot(nc, cluster)\n",
    "    return np.concatenate((cluster_hot, site_hot(cluster, site)))\n",
    "\n",
    "\n",
    "def gen_label(cluster, site):\n",
    "    p = rr_s(cluster, site)\n",
    "    return (np.random.uniform() < p)*1\n",
    "\n",
    "\n",
    "def gen_row(cluster):\n",
    "    p_sites = p_s[cluster]\n",
    "    site = np.random.choice(len(p_sites), 1, list(p_sites))[0]\n",
    "    return np.concatenate( (encode(cluster, site), [gen_label(cluster, site)] ))\n",
    "\n",
    "def gen_data(N=100):\n",
    "    clusters = np.random.choice(3, N, list(p_c))\n",
    "    return np.array(list(map(gen_row, clusters)))\n",
    "\n",
    "obs_data = gen_data(N=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR model with site + cluster indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.51976795, -1.38629436],\n",
       "       [-0.55311066, -1.38629436],\n",
       "       [-0.02933708,  0.61370564],\n",
       "       [-1.0696598 , -1.38629436],\n",
       "       [-0.98446862, -1.38629436],\n",
       "       [-0.59977762, -1.38629436],\n",
       "       [-0.10441875,  0.40546511],\n",
       "       [-0.10441875,  0.40546511],\n",
       "       [ 0.8519067 ,  0.40546511],\n",
       "       [-1.97519099, -2.19722458],\n",
       "       [-2.4380698 , -7.19722458],\n",
       "       [-2.126541  , -2.19722458]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### LR with site + cluster indicators\n",
    "lr_sc = LogisticRegression(fit_intercept = False)\n",
    "# model with cluster_ids\n",
    "lr_sc.fit(obs_data[:,:-1], obs_data[:,-1])\n",
    "# get the equivalent site-only weights:\n",
    "lr_w_s = site_weights(lr_sc.coef_[0])\n",
    "\n",
    "# compare these with w_s (true weights with sites-only)\n",
    "\n",
    "np.c_[ lr_w_s, w_s]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR model with only site indicators\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.33540625, -1.38629436],\n",
       "       [-0.40396376, -1.38629436],\n",
       "       [ 0.40105801,  0.61370564],\n",
       "       [-0.82641745, -1.38629436],\n",
       "       [-0.79666131, -1.38629436],\n",
       "       [-0.28654723, -1.38629436],\n",
       "       [-0.15405659,  0.40546511],\n",
       "       [-0.15405659,  0.40546511],\n",
       "       [ 0.79666131,  0.40546511],\n",
       "       [-1.31964724, -2.19722458],\n",
       "       [-1.63350602, -7.19722458],\n",
       "       [-1.51753773, -2.19722458]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LR with only site indicators\n",
    "lr_s = LogisticRegression(fit_intercept = False)\n",
    "lr_s.fit(obs_data[:,n_c:-1], obs_data[:,-1])\n",
    "\n",
    "# compare these with w_s (true weights with just sites)\n",
    "np.c_[ lr_s.coef_[0], w_s]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions to look into\n",
    "\n",
    "Recall the 2 x 2 x 2 combination of approaches:\n",
    "\n",
    "- TrainModel: Train_LR / Train_Complex\n",
    "- ScoreModel: Score_LR / Score_Complex\n",
    "- ScoreFeatures: Score_Clusters / Score_NoClusters\n",
    "\n",
    "Specific question:\n",
    "- **Train_LR, Score_LR, Score_NoClusters** Is it possible to use LR for training (with both site_ids and cluster_id indicators) and get a useful ScoreModel with NoClusters, by essentially augmenting the learned site_weight with its cluster_weight.\n",
    "- If not, then can **Train_Complex, Score_LR, Score_NoClusters** give a good model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
