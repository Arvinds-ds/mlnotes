{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.stats import logistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clusters and site parameters\n",
    "\n",
    "We will define 3 clusters, each with 3 sites.\n",
    "\n",
    "We will think of each cluster as having a \"baseline\" response-rate, and the sites within each cluster vary \"around\" that baseline. We cannot do this in probability space (since we need to stay within [0,1]), but we can easily do this \"variation from baseline\" in logit space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_c = np.array([0.2, 0.2, 0.6])  # prob of each cluster occurring\n",
    "n_c = len(p_c)\n",
    "rr_c = np.array([0.2, 0.6, 0.1])  # baseline response-rates of each cluster\n",
    "\n",
    "w_c = np.log(rr_c/ (1.0 - rr_c)) # logits of the clusters, corresponding to their baseline rates\n",
    "\n",
    "p_s = [ np.array([0.1, 0.4, 0.5]),  # site occurrence probabilities, in each cluster\n",
    "        np.array([0.3, 0.3, 0.4]),\n",
    "        np.array([0.2, 0.2, 0.6])\n",
    "        ]\n",
    "\n",
    "# Each site_id adds to the cluster's baseline logit;\n",
    "# Cluster members generally have cluster's baseline RR,\n",
    "# except for some that are \"much higher\" or \"much lower\".\n",
    "# We cannot express this in probabilities easily (since they need to be in [0,1]\n",
    "# but in logit (or log-oods) space this is easy.\n",
    "# Think of these as \"incremental\" site_weights, relative to their cluster-weight\n",
    "# So we name these as \"d_w_s\" , signifying \"delta site weight\"\n",
    "d_w_s = [ np.array( [0.0, 0.0, 2.0]),  # cluster 1\n",
    "          np.array( [0.0, 0.0, 0.0]),  # cluster 2\n",
    "          np.array( [0.0, -5.0, 0.0])  # cluster 3\n",
    "          ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### True model with site + cluster indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.38629436,  0.40546511, -2.19722458,  0.        ,  0.        ,\n",
       "        2.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "       -5.        ,  0.        ])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# site + cluster model with these indicator variables:\n",
    "# c_1, c_2, c_3, s_11, s_12, s_13, s_21, s_21, s_23, s_31, s_32, s_33\n",
    "\n",
    "w_site = np.concatenate( [ d_w_s[i] for i in range(3)] )\n",
    "w_sc = np.concatenate((w_c, w_site))\n",
    "w_sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equivalent true model with sites only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.38629436, -1.38629436,  0.61370564,  0.40546511,  0.40546511,\n",
       "        0.40546511, -2.19722458, -7.19722458, -2.19722458])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## convert (cluster + sites) weight-vector to (site-only) weights\n",
    "def site_weights(wts):\n",
    "    w_clusters = wts[:n_c]\n",
    "    w_sites = wts[n_c:]\n",
    "    w_clusters_rep = np.concatenate( [  [ w_clusters[i] ] * len (p_s[i]) for i in range(n_c)])\n",
    "    return w_sites + w_clusters_rep\n",
    "\n",
    "w_s = site_weights(w_sc )\n",
    "w_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data gen \n",
    "We generate N rows with one-hot encoded clusters and sites:\n",
    "\n",
    "`c_1, c_2, c_3, s_11, s_12, s_13, s_21, s_21, s_23, s_31, s_32, s_33, label`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(n, i):\n",
    "    x = np.array([0] * n)\n",
    "    x[i] = 1.0\n",
    "    return x\n",
    "\n",
    "\n",
    "# site-indicator variables for all clusters,\n",
    "# given that a specific cluster and its site occur\n",
    "def site_hot(cluster, site):\n",
    "    nc = len(p_c)\n",
    "    ns = len(p_s[cluster])  # num sites in this cluster\n",
    "    return np.concatenate(\n",
    "        [one_hot(len(p_s[c]), site)\n",
    "         if c == cluster\n",
    "         else one_hot(len(p_s[c]), 0) * 0\n",
    "         for c in range(nc)]\n",
    "    )\n",
    "\n",
    "\n",
    "# encode data-row given cluster index, site_index in cluster\n",
    "def encode(cluster, site):\n",
    "    nc = len(p_c)\n",
    "    cluster_hot = one_hot(nc, cluster)\n",
    "    return np.concatenate((cluster_hot, site_hot(cluster, site)))\n",
    "\n",
    "# logit for a given cluster and one of its sites\n",
    "def logit_site(cluster, site):\n",
    "    return w_c[cluster] + d_w_s[cluster][site]\n",
    "\n",
    "\n",
    "def gen_label(cluster, site):\n",
    "    p = logistic.cdf(logit_site(cluster, site))\n",
    "    return (np.random.uniform() < p)*1\n",
    "\n",
    "\n",
    "def gen_row(cluster):\n",
    "    p_sites = p_s[cluster]\n",
    "    site = np.random.choice(len(p_sites), 1, list(p_sites))[0]\n",
    "    return np.concatenate( (encode(cluster, site), [gen_label(cluster, site)] ))\n",
    "\n",
    "def gen_data(N=100):\n",
    "    clusters = np.random.choice(3, N, list(p_c))\n",
    "    return np.array(list(map(gen_row, clusters)))\n",
    "\n",
    "obs_data = gen_data(N=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR model with site + cluster indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### LR with site + cluster indicators\n",
    "lr_sc = LogisticRegression()\n",
    "# model with cluster_ids\n",
    "lr_sc.fit(obs_data[:,:-1], obs_data[:,-1])\n",
    "# get the equivalent site-only weights:\n",
    "lr_w_s = site_weights(lr_sc.coef_[0])\n",
    "lr_w_s\n",
    "# compare these with w_s (true weights with sites-only)\n",
    "w_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR model with only site indicators\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LR with only site indicators\n",
    "n_c = len(p_c)\n",
    "lr_s = LogisticRegression()\n",
    "lr_s.fit(obs_data[:,n_c:-1], obs_data[:,-1])\n",
    "\n",
    "# compare these with w_s (true weights with just sites)\n",
    "lr_s.coef_\n",
    "w_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions to look into\n",
    "\n",
    "Recall the 2 x 2 x 2 combination of approaches:\n",
    "\n",
    "- TrainModel: Train_LR / Train_Complex\n",
    "- ScoreModel: Score_LR / Score_Complex\n",
    "- ScoreFeatures: Score_Clusters / Score_NoClusters\n",
    "\n",
    "Specific question:\n",
    "- **Train_LR, Score_LR, Score_NoClusters** Is it possible to use LR for training (with both site_ids and cluster_id indicators) and get a useful ScoreModel with NoClusters, by essentially augmenting the learned site_weight with its cluster_weight.\n",
    "- If not, then can **Train_Complex, Score_LR, Score_NoClusters** give a good model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
