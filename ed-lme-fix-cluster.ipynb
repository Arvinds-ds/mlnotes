{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Linear Mixed Effects Models -- modified Edward tutorial for grouped model\n",
    "\n",
    "### This version uses fixed effects for clusters, random effects for sites\n",
    "\n",
    "\n",
    "With linear mixed effects models, we wish to model a linear\n",
    "relationship for data points with inputs of varying type, categorized\n",
    "into subgroups, and associated to a real-valued output.\n",
    "\n",
    "We demonstrate with an example in Edward. A webpage version is available \n",
    "[here](http://edwardlib.org/tutorials/linear-mixed-effects-models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": true,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import edward as ed\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from edward.models import Normal, BernoulliWithSigmoidProbs, Bernoulli\n",
    "from observations import insteval\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.stats import logistic\n",
    "\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "ed.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Data: Clusters and site parameters\n",
    "\n",
    "We will define 3 clusters, each with some number of member sites.\n",
    "\n",
    "The data-generating model follows a very simple premise:\n",
    "> Within each cluster, the sites will have a \"default\" or \"baseline\" RR (response-rate), and sites within a cluster will exhibit variation around this cluster-default.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# site, cluster occurrence probabilities, to generate the dataset\n",
    "# as well as their \"true\" logit-weights \n",
    "\n",
    "clusters = {0: dict(prob = 0.2, w = -0.5,   # cluster weight in logistic\n",
    "                    sites = np.arange(6),     \n",
    "                    site_probs = [0.1, 0.1, 0.1, 0.1, 0.1, 0.5],\n",
    "                    w_s =        [0.0, 0.0, 0.0, 5.0, 0.0, 0.0]),  # weights of sites in logistic\n",
    "            1: dict(prob = 0.5, w = -1.0,  \n",
    "                    sites = 6 + np.arange(3), \n",
    "                    site_probs = [0.1, 0.3, 0.6],\n",
    "                    w_s        = [0.0, 0.0, 0.0]),                    \n",
    "            2: dict(prob = 0.3, w = -0.2,  \n",
    "                    sites = 9 + np.arange(3), \n",
    "                    site_probs = [0.3, 0.3, 0.4] ,\n",
    "                    w_s =        [0.0, -4, 0.0 ]\n",
    "                   )}\n",
    "\n",
    "\n",
    "# num clusters\n",
    "n_c = len(clusters)\n",
    "\n",
    "# num sites\n",
    "n_s = sum(list( map(len, list( map( lambda d: d['sites'], clusters.values()))))) # num sites\n",
    "\n",
    "# site to cluster map\n",
    "s2c = dict( [ (s,c) for c in range(n_c) for s in clusters[c]['sites']] )\n",
    "\n",
    "# prob of each cluster occurring\n",
    "p_c = [c['prob'] for c in clusters.values()]\n",
    "\n",
    "# prob of site occurrence, within a cluster\n",
    "\n",
    "p_s = ( [  dict( zip (d['sites'], d['site_probs']))  for d in clusters.values() ])\n",
    "\n",
    "# \"true\" weights of clusters in logit model\n",
    "w_c = np.array( [d['w'] for d in clusters.values()] )\n",
    "\n",
    "# \"true\" weights of sites in logit model\n",
    "w_s = np.concatenate( [d['w_s'] for d in clusters.values() ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## True weights of logistic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logit for a site: sum of site-weight and its cluster-weight\n",
    "def logit_site(site):\n",
    "    return w_c[s2c[site]] + w_s[site]\n",
    "\n",
    "# site response_rate\n",
    "def rr_s(site):\n",
    "    return logistic.cdf(logit_site(site))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Site response-rates\n",
    "Note how this matches what we wanted to model, i.e. in each cluster sites have a certain \"baseline\" response rate (RR), and some have much higher or much lower RR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3775,\n",
       " 0.3775,\n",
       " 0.3775,\n",
       " 0.989,\n",
       " 0.3775,\n",
       " 0.3775,\n",
       " 0.2689,\n",
       " 0.2689,\n",
       " 0.2689,\n",
       " 0.4502,\n",
       " 0.0148,\n",
       " 0.4502]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[np.round(rr_s(s),4) for s in range(n_s) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data gen \n",
    "We generate N rows with `[cluster_id, site_id, abel]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_label(site):\n",
    "    p = rr_s(site)\n",
    "    return (np.random.uniform() < p)*1\n",
    "\n",
    "\n",
    "def gen_row(cluster):\n",
    "    site2prob = p_s[cluster]\n",
    "    site_ids = list( site2prob.keys())\n",
    "    probs = list(site2prob.values())\n",
    "    site = site_ids[ np.random.choice(len(probs), 1, probs ) [0] ]\n",
    "    return np.array( [ cluster, site, gen_label(site)] )\n",
    "\n",
    "def gen_data(N=100):\n",
    "    clusters = np.random.choice(n_c, N, list(p_c))\n",
    "    return np.array(list(map(gen_row, clusters)))\n",
    "\n",
    "train = gen_data(N=1000)\n",
    "test = gen_data(N=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2, 11,  1],\n",
       "       [ 0,  4,  0],\n",
       "       [ 2, 11,  0],\n",
       "       [ 2, 11,  0],\n",
       "       [ 0,  5,  0],\n",
       "       [ 0,  5,  1],\n",
       "       [ 2, 11,  0],\n",
       "       [ 1,  7,  0],\n",
       "       [ 2, 10,  0],\n",
       "       [ 2,  9,  1]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": true,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "c_train = train[:,0]\n",
    "s_train = train[:,1]\n",
    "y_train = train[:,2]\n",
    "n_obs_train = train.shape[0]\n",
    "\n",
    "c_test = test[:,0]\n",
    "s_test = test[:,1]\n",
    "y_test = np.array(test[:,2]).astype(np.int32)\n",
    "n_obs_test = test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "autoscroll": "json-false",
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sites: 12\n",
      "Number of clusters: 3\n",
      "Number of observations: 1000\n"
     ]
    }
   ],
   "source": [
    "n_s = max(s_train) + 1  # number of sites\n",
    "n_c = max(c_train) + 1  # number of clusters\n",
    "n_obs = train.shape[0]  # number of observations\n",
    "\n",
    "print(\"Number of sites: {}\".format(n_s))\n",
    "print(\"Number of clusters: {}\".format(n_c))\n",
    "print(\"Number of observations: {}\".format(n_obs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Model\n",
    "\n",
    "Since our problem is binary classification (convert or not), we use a logistic regression where we model the _log-odds_ as a linear function of predictors.\n",
    "\n",
    "In what follows we let $z$ denote the log-odds, and the actual prediction itself will be $1/(1+e^{-z})$.\n",
    "\n",
    "\n",
    "```\n",
    "z ~ (1|site) + cluster\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": true,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Set up placeholders for the data inputs.\n",
    "s_ph = tf.placeholder(tf.int32, [None])\n",
    "c_ph = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "# Set up random effects.\n",
    "\n",
    "sigma_s = tf.sqrt(tf.exp(tf.get_variable(\"sigma_s\", [])))  # random effect for a site\n",
    "beta_c = tf.get_variable(\"sigma_c\", [n_c])  # fixed effect for cluster\n",
    "\n",
    "eta_s = Normal(loc=tf.zeros(n_s), scale=sigma_s * tf.ones(n_s))\n",
    "\n",
    "\n",
    "yhat = (tf.gather(eta_s, s_ph) + # pick the entry from eta_s using site-index fed into placeholder s_ph \n",
    "        tf.gather(beta_c, c_ph))  # same thing with cluster-index fed into placeholder c_ph\n",
    "\n",
    "# y_logit = Normal(loc=yhat, scale=tf.ones(n_obs))\n",
    "\n",
    "y = Bernoulli(logits = yhat)\n",
    "\n",
    "\n",
    "\n",
    "# y = tf.sigmoid(y_logit)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Inference\n",
    "\n",
    "Given data, we aim to infer the model's fixed and random effects.\n",
    "In this analysis, we use variational inference with the\n",
    "$\\text{KL}(q\\|p)$ divergence measure. We specify fully factorized\n",
    "normal approximations for the random effects and pass in all training\n",
    "data for inference. Under the algorithm, the fixed effects will be\n",
    "estimated under a variational EM scheme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": true,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Key-value pair in latent_vars does not have same shape: (12,), (3,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-ec6b5ee43dd3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0minference\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0med\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKLqp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/tfbrain/lib/python3.6/site-packages/edward/inferences/klqp.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, latent_vars, data)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mlatent_vars_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKLqp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkl_scaling\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/tfbrain/lib/python3.6/site-packages/edward/inferences/variational_inference.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m   \"\"\"\n\u001b[1;32m     26\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariationalInference\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m   def initialize(self, optimizer=None, var_list=None, use_prettytensor=False,\n",
      "\u001b[0;32m~/miniconda/envs/tfbrain/lib/python3.6/site-packages/edward/inferences/inference.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, latent_vars, data)\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0mcheck_latent_vars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatent_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlatent_vars\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/tfbrain/lib/python3.6/site-packages/edward/util/random_variables.py\u001b[0m in \u001b[0;36mcheck_latent_vars\u001b[0;34m(latent_vars)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m       raise TypeError(\"Key-value pair in latent_vars does not have same \"\n\u001b[0;32m---> 80\u001b[0;31m                       \"shape: {}, {}\".format(key.shape, value.shape))\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m       raise TypeError(\"Key-value pair in latent_vars does not have same \"\n",
      "\u001b[0;31mTypeError\u001b[0m: Key-value pair in latent_vars does not have same shape: (12,), (3,)"
     ]
    }
   ],
   "source": [
    "q_eta_s = Normal(\n",
    "    loc=tf.get_variable(\"q_eta_s/loc\", [n_c]),\n",
    "    scale=tf.nn.softplus(tf.get_variable(\"q_eta_s/scale\", [n_c])))\n",
    "\n",
    "latent_vars = {eta_s: q_eta_s}\n",
    "\n",
    "data = {\n",
    "    y: y_train,\n",
    "    s_ph: s_train,\n",
    "    c_ph: c_train}\n",
    "\n",
    "\n",
    "inference = ed.KLqp(latent_vars, data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criticism\n",
    "\n",
    "We will evaluate the inferred distributions by computing logits from the means of the inferred posterior distributions of the latent vars. From the logits we can compute the log-loss relative to the observed 0/1 labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": true,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "yhat_test = ed.copy(yhat, {eta_s: q_eta_s.mean() })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_loss(labels, probs):\n",
    "    return -np.mean(labels * np.log(probs) + (1-labels)*np.log(1-probs))\n",
    "\n",
    "def rig(labels, probs):\n",
    "    p = np.mean(labels)\n",
    "    ent = -p*np.log(p) - (1-p)*np.log(1-p)\n",
    "    loss = log_loss(labels, probs)\n",
    "    return np.round(100*(ent - loss)/ent, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "autoscroll": "json-false",
    "ein.tags": [
     "worksheet-0"
    ],
    "scrolled": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "indices[0] = 11 is not in [0, 3)\n\t [[Node: inference/sample/Gather_1 = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](inference/sample/sigma_c/read, _arg_Placeholder_0_0)]]\n\nCaused by op 'inference/sample/Gather_1', defined at:\n  File \"/Users/pchalasani/miniconda/envs/tfbrain/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/pchalasani/miniconda/envs/tfbrain/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/pchalasani/miniconda/envs/tfbrain/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/pchalasani/miniconda/envs/tfbrain/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/pchalasani/miniconda/envs/tfbrain/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/Users/pchalasani/miniconda/envs/tfbrain/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/pchalasani/miniconda/envs/tfbrain/lib/python3.6/site-packages/tornado/ioloop.py\", line 866, in start\n    handler_func(fd_obj, events)\n  File \"/Users/pchalasani/miniconda/envs/tfbrain/lib/python3.6/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/pchalasani/miniconda/envs/tfbrain/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Users/pchalasani/miniconda/envs/tfbrain/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/pchalasani/miniconda/envs/tfbrain/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/pchalasani/miniconda/envs/tfbrain/lib/python3.6/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/pchalasani/miniconda/envs/tfbrain/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/pchalasani/miniconda/envs/tfbrain/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/pchalasani/miniconda/envs/tfbrain/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/pchalasani/miniconda/envs/tfbrain/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/pchalasani/miniconda/envs/tfbrain/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/pchalasani/miniconda/envs/tfbrain/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/pchalasani/miniconda/envs/tfbrain/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/pchalasani/miniconda/envs/tfbrain/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-13-bee157463649>\", line 1, in <module>\n    inference.initialize(n_print=2000, n_iter=20000)\n  File \"/Users/pchalasani/miniconda/envs/tfbrain/lib/python3.6/site-packages/edward/inferences/klqp.py\", line 110, in initialize\n    return super(KLqp, self).initialize(*args, **kwargs)\n  File \"/Users/pchalasani/miniconda/envs/tfbrain/lib/python3.6/site-packages/edward/inferences/variational_inference.py\", line 68, in initialize\n    self.loss, grads_and_vars = self.build_loss_and_gradients(var_list)\n  File \"/Users/pchalasani/miniconda/envs/tfbrain/lib/python3.6/site-packages/edward/inferences/klqp.py\", line 145, in build_loss_and_gradients\n    return build_reparam_kl_loss_and_gradients(self, var_list)\n  File \"/Users/pchalasani/miniconda/envs/tfbrain/lib/python3.6/site-packages/edward/inferences/klqp.py\", line 722, in build_reparam_kl_loss_and_gradients\n    x_copy = copy(x, dict_swap, scope=scope)\n  File \"/Users/pchalasani/miniconda/envs/tfbrain/lib/python3.6/site-packages/edward/util/random_variables.py\", line 246, in copy\n    value, dict_swap, scope, True, copy_q, False)\n  File \"/Users/pchalasani/miniconda/envs/tfbrain/lib/python3.6/site-packages/edward/util/random_variables.py\", line 88, in _copy_default\n    x = copy(x, *args, **kwargs)\n  File \"/Users/pchalasani/miniconda/envs/tfbrain/lib/python3.6/site-packages/edward/util/random_variables.py\", line 270, in copy\n    new_op = copy(op, dict_swap, scope, True, copy_q, False)\n  File \"/Users/pchalasani/miniconda/envs/tfbrain/lib/python3.6/site-packages/edward/util/random_variables.py\", line 334, in copy\n    elem = copy(x, dict_swap, scope, True, copy_q, False)\n  File \"/Users/pchalasani/miniconda/envs/tfbrain/lib/python3.6/site-packages/edward/util/random_variables.py\", line 270, in copy\n    new_op = copy(op, dict_swap, scope, True, copy_q, False)\n  File \"/Users/pchalasani/miniconda/envs/tfbrain/lib/python3.6/site-packages/edward/util/random_variables.py\", line 316, in copy\n    op_def)\n  File \"/Users/pchalasani/miniconda/envs/tfbrain/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1625, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): indices[0] = 11 is not in [0, 3)\n\t [[Node: inference/sample/Gather_1 = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](inference/sample/sigma_c/read, _arg_Placeholder_0_0)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda/envs/tfbrain/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/tfbrain/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/tfbrain/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: indices[0] = 11 is not in [0, 3)\n\t [[Node: inference/sample/Gather_1 = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](inference/sample/sigma_c/read, _arg_Placeholder_0_0)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-bee157463649>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;31m# Update and print progress of algorithm.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0minfo_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0minference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/tfbrain/lib/python3.6/site-packages/edward/inferences/variational_inference.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, feed_dict)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mincrement_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/tfbrain/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/tfbrain/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1128\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1129\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/tfbrain/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1344\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/tfbrain/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1362\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1363\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1365\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: indices[0] = 11 is not in [0, 3)\n\t [[Node: inference/sample/Gather_1 = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](inference/sample/sigma_c/read, _arg_Placeholder_0_0)]]\n\nCaused by op 'inference/sample/Gather_1', defined at:\n  File \"/Users/pchalasani/miniconda/envs/tfbrain/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/pchalasani/miniconda/envs/tfbrain/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/pchalasani/miniconda/envs/tfbrain/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/pchalasani/miniconda/envs/tfbrain/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/pchalasani/miniconda/envs/tfbrain/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/Users/pchalasani/miniconda/envs/tfbrain/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/pchalasani/miniconda/envs/tfbrain/lib/python3.6/site-packages/tornado/ioloop.py\", line 866, in start\n    handler_func(fd_obj, events)\n  File \"/Users/pchalasani/miniconda/envs/tfbrain/lib/python3.6/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/pchalasani/miniconda/envs/tfbrain/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Users/pchalasani/miniconda/envs/tfbrain/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/pchalasani/miniconda/envs/tfbrain/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/pchalasani/miniconda/envs/tfbrain/lib/python3.6/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/pchalasani/miniconda/envs/tfbrain/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/pchalasani/miniconda/envs/tfbrain/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/pchalasani/miniconda/envs/tfbrain/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/pchalasani/miniconda/envs/tfbrain/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/pchalasani/miniconda/envs/tfbrain/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/pchalasani/miniconda/envs/tfbrain/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/pchalasani/miniconda/envs/tfbrain/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/pchalasani/miniconda/envs/tfbrain/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-13-bee157463649>\", line 1, in <module>\n    inference.initialize(n_print=2000, n_iter=20000)\n  File \"/Users/pchalasani/miniconda/envs/tfbrain/lib/python3.6/site-packages/edward/inferences/klqp.py\", line 110, in initialize\n    return super(KLqp, self).initialize(*args, **kwargs)\n  File \"/Users/pchalasani/miniconda/envs/tfbrain/lib/python3.6/site-packages/edward/inferences/variational_inference.py\", line 68, in initialize\n    self.loss, grads_and_vars = self.build_loss_and_gradients(var_list)\n  File \"/Users/pchalasani/miniconda/envs/tfbrain/lib/python3.6/site-packages/edward/inferences/klqp.py\", line 145, in build_loss_and_gradients\n    return build_reparam_kl_loss_and_gradients(self, var_list)\n  File \"/Users/pchalasani/miniconda/envs/tfbrain/lib/python3.6/site-packages/edward/inferences/klqp.py\", line 722, in build_reparam_kl_loss_and_gradients\n    x_copy = copy(x, dict_swap, scope=scope)\n  File \"/Users/pchalasani/miniconda/envs/tfbrain/lib/python3.6/site-packages/edward/util/random_variables.py\", line 246, in copy\n    value, dict_swap, scope, True, copy_q, False)\n  File \"/Users/pchalasani/miniconda/envs/tfbrain/lib/python3.6/site-packages/edward/util/random_variables.py\", line 88, in _copy_default\n    x = copy(x, *args, **kwargs)\n  File \"/Users/pchalasani/miniconda/envs/tfbrain/lib/python3.6/site-packages/edward/util/random_variables.py\", line 270, in copy\n    new_op = copy(op, dict_swap, scope, True, copy_q, False)\n  File \"/Users/pchalasani/miniconda/envs/tfbrain/lib/python3.6/site-packages/edward/util/random_variables.py\", line 334, in copy\n    elem = copy(x, dict_swap, scope, True, copy_q, False)\n  File \"/Users/pchalasani/miniconda/envs/tfbrain/lib/python3.6/site-packages/edward/util/random_variables.py\", line 270, in copy\n    new_op = copy(op, dict_swap, scope, True, copy_q, False)\n  File \"/Users/pchalasani/miniconda/envs/tfbrain/lib/python3.6/site-packages/edward/util/random_variables.py\", line 316, in copy\n    op_def)\n  File \"/Users/pchalasani/miniconda/envs/tfbrain/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1625, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): indices[0] = 11 is not in [0, 3)\n\t [[Node: inference/sample/Gather_1 = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](inference/sample/sigma_c/read, _arg_Placeholder_0_0)]]\n"
     ]
    }
   ],
   "source": [
    "inference.initialize(n_print=2000, n_iter=20000)\n",
    "\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "\n",
    "for _ in range(inference.n_iter):\n",
    "  # Update and print progress of algorithm.\n",
    "  info_dict = inference.update()\n",
    "\n",
    "  inference.print_progress(info_dict)\n",
    "\n",
    "  t = info_dict['t']\n",
    "  if t == 1 or t % inference.n_print == 0:\n",
    "    # Make predictions on test data.\n",
    "    yhat_vals = yhat_test.eval(feed_dict={\n",
    "        s_ph: s_test,\n",
    "        c_ph: c_test})\n",
    "\n",
    "    probs = logistic.cdf(yhat_vals)\n",
    "    rg  = rig(y_test, probs)\n",
    "    \n",
    "    print('rig=', rg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    1/10000 [  0%]                                ETA: 7054s | Loss: 675.057rig= -10.78\n",
      " 2000/10000 [ 20%] ██████                         ETA: 9s | Loss: 575.155   rig= 12.61\n",
      " 4000/10000 [ 40%] ████████████                   ETA: 6s | Loss: 578.508rig= 12.48\n",
      " 6000/10000 [ 60%] ██████████████████             ETA: 3s | Loss: 579.477rig= 12.51\n",
      " 8000/10000 [ 80%] ████████████████████████       ETA: 1s | Loss: 575.550rig= 12.52\n",
      "10000/10000 [100%] ██████████████████████████████ Elapsed: 8s | Loss: 577.369\n",
      "rig= 12.52\n"
     ]
    }
   ],
   "source": [
    "inference_s.initialize(n_print=2000, n_iter=10000)\n",
    "\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "\n",
    "for _ in range(inference_s.n_iter):\n",
    "  # Update and print progress of algorithm.\n",
    "  info_dict = inference_s.update()\n",
    "\n",
    "  inference_s.print_progress(info_dict)\n",
    "\n",
    "  t = info_dict['t']\n",
    "  if t == 1 or t % inference.n_print == 0:\n",
    "    # Make predictions on test data.\n",
    "    yhat_vals = yhat_test_s.eval(feed_dict={\n",
    "        s_ph: s_test})\n",
    "\n",
    "\n",
    "    probs = logistic.cdf(yhat_vals)\n",
    "    rg  = rig(y_test, probs)\n",
    "    \n",
    "    print('rig=', rg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare with MLE logistic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "name": "linear_mixed_effects_models.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
